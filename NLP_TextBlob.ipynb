{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cea928d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a01640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob=TextBlob(\"Analytics is a great platform to learn data science. \\n It helps community through blogs, hackathons, discussions,etc.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c68633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Analytics is a great platform to learn data science.\"),\n",
       " Sentence(\"It helps community through blogs, hackathons, discussions,etc.\")]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Analytics is a great platform to learn data science.\"),\n",
       " Sentence(\"It helps community through blogs, hackathons, discussions,etc.\")]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a523d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence(\"Analytics is a great platform to learn data science.\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Sentence(\"Analytics is a great platform to learn data science.\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentences[0] #extracting only first sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52d629af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytics\n",
      "is\n",
      "a\n",
      "great\n",
      "platform\n",
      "to\n",
      "learn\n",
      "data\n",
      "science\n",
      "Analytics\n",
      "is\n",
      "a\n",
      "great\n",
      "platform\n",
      "to\n",
      "learn\n",
      "data\n",
      "science\n"
     ]
    }
   ],
   "source": [
    "for words in blob.sentences[0].words: #printing words of first senence\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc95058f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analytics\n",
      "great platform\n",
      "data science\n",
      "analytics\n",
      "great platform\n",
      "data science\n"
     ]
    }
   ],
   "source": [
    "blob=TextBlob(\"Analytics is a great platform to learn data science.\")\n",
    "for np in blob.noun_phrases:\n",
    "    print(np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78b4754c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytics NNS\n",
      "is VBZ\n",
      "a DT\n",
      "great JJ\n",
      "platform NN\n",
      "to TO\n",
      "learn VB\n",
      "data NNS\n",
      "science NN\n",
      "Analytics NNS\n",
      "is VBZ\n",
      "a DT\n",
      "great JJ\n",
      "platform NN\n",
      "to TO\n",
      "learn VB\n",
      "data NNS\n",
      "science NN\n"
     ]
    }
   ],
   "source": [
    "for words, tag in blob.tags:\n",
    "    print(words, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0e9b428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helps\n",
      "help\n",
      "helps\n",
      "help\n"
     ]
    }
   ],
   "source": [
    "blob=TextBlob(\"Analytics is a great platform to learn data science.\\n It helps community through blogs, hackathons, discussions,etc.\")\n",
    "print(blob.sentences[1].words[1])\n",
    "print(blob.sentences[1].words[1].singularize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9c23f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "platforms\n",
      "sciences\n",
      "communities\n",
      "platforms\n",
      "sciences\n",
      "communities\n"
     ]
    }
   ],
   "source": [
    "#using tags\n",
    "for word,pos in blob.tags:\n",
    "    if pos=='NN':\n",
    "        print(word.pluralize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66a63c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Analytics', 'is', 'a']\n",
      "['is', 'a', 'great']\n",
      "['a', 'great', 'platform']\n",
      "['great', 'platform', 'to']\n",
      "['platform', 'to', 'learn']\n",
      "['to', 'learn', 'data']\n",
      "['learn', 'data', 'science']\n",
      "['data', 'science', 'It']\n",
      "['science', 'It', 'helps']\n",
      "['It', 'helps', 'community']\n",
      "['helps', 'community', 'through']\n",
      "['community', 'through', 'blogs']\n",
      "['through', 'blogs', 'hackathons']\n",
      "['blogs', 'hackathons', 'discussions']\n",
      "['hackathons', 'discussions', 'etc']\n",
      "['Analytics', 'is', 'a']\n",
      "['is', 'a', 'great']\n",
      "['a', 'great', 'platform']\n",
      "['great', 'platform', 'to']\n",
      "['platform', 'to', 'learn']\n",
      "['to', 'learn', 'data']\n",
      "['learn', 'data', 'science']\n",
      "['data', 'science', 'It']\n",
      "['science', 'It', 'helps']\n",
      "['It', 'helps', 'community']\n",
      "['helps', 'community', 'through']\n",
      "['community', 'through', 'blogs']\n",
      "['through', 'blogs', 'hackathons']\n",
      "['blogs', 'hackathons', 'discussions']\n",
      "['hackathons', 'discussions', 'etc']\n"
     ]
    }
   ],
   "source": [
    "for ngram in blob.ngrams(3):\n",
    "    print(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "551e0875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytics is a great platform to learn data science.\n",
      " It helps community through blogs, hackathons, discussions,etc.\n",
      "Analytics is a great platform to learn data science.\n",
      " It helps community through blogs, hackathons, discussions,etc.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.8, subjectivity=0.75)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.8, subjectivity=0.75)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(blob)\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91982761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Analytics is a great platform to learn data science\")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Analytics is a great platform to learn data science\")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spelling correction\n",
    "blob=TextBlob('Analytics is a gret platfrm to learn dta scence')\n",
    "blob.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17fc0472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.5351351351351351),\n",
       " ('get', 0.3162162162162162),\n",
       " ('grew', 0.11216216216216217),\n",
       " ('grey', 0.026351351351351353),\n",
       " ('greet', 0.006081081081081081),\n",
       " ('fret', 0.002702702702702703),\n",
       " ('grit', 0.0006756756756756757),\n",
       " ('cret', 0.0006756756756756757)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('great', 0.5351351351351351),\n",
       " ('get', 0.3162162162162162),\n",
       " ('grew', 0.11216216216216217),\n",
       " ('grey', 0.026351351351351353),\n",
       " ('greet', 0.006081081081081081),\n",
       " ('fret', 0.002702702702702703),\n",
       " ('grit', 0.0006756756756756757),\n",
       " ('cret', 0.0006756756756756757)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check list of suggested word and its confidence using spellcheck function\n",
    "blob.words[3].spellcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "063d84fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob('Analytics is a thriving community for data driven industry. This platform allows \\\n",
    "people to know more about analytics from its articles, Q&A forum, and learning paths. Also, we help \\\n",
    "professionals & amateurs to sharpen their skillsets by providing a platform to participate in Hackathons.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c46822ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n",
      "this text is about ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'noun' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-ec749906a2f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mnouns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'this text is about ...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoun\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mWord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpluralize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'noun' is not defined"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'noun' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-ec749906a2f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mnouns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'this text is about ...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoun\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mWord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpluralize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'noun' is not defined"
     ]
    }
   ],
   "source": [
    "#creating a short summary of text\n",
    "import random\n",
    "nouns=list()\n",
    "for word, tag in blob.tags:\n",
    "    if tag=='NN':\n",
    "        nouns.append(word.lemmatize())\n",
    "    print('this text is about ...')\n",
    "for item in random.sample(noun,5):\n",
    "    word=Word(item)\n",
    "print(word.pluralize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61f498b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text classification using TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22bf0e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = [\n",
    "('Tom Holland is a terrible spiderman.','pos'),\n",
    "('a terrible Javert (Russell Crowe) ruined Les Miserables for me...','pos'),\n",
    "('The Dark Knight Rises is the greatest superhero movie ever!','neg'),\n",
    "('Fantastic Four should have never been made.','pos'),\n",
    "('Wes Anderson is my favorite director!','neg'),\n",
    "('Captain America 2 is pretty awesome.','neg'),\n",
    "('Let\\s pretend \"Batman and Robin\" never happened..','pos'),\n",
    "]\n",
    "\n",
    "testing = [\n",
    "('Superman was never an interesting character.','pos'),\n",
    "('Fantastic Mr Fox is an awesome film!','neg'),\n",
    "('Dragonball Evolution is simply terrible!!','pos')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e506559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cdf07693",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=classifiers.NaiveBayesClassifier(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "696df103",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier=classifiers.DecisionTreeClassifier(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b12fb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Most Informative Features\n",
      "            contains(is) = True              neg : pos    =      2.9 : 1.0\n",
      "             contains(a) = False             neg : pos    =      1.8 : 1.0\n",
      "         contains(never) = False             neg : pos    =      1.8 : 1.0\n",
      "1.0\n",
      "Most Informative Features\n",
      "            contains(is) = True              neg : pos    =      2.9 : 1.0\n",
      "             contains(a) = False             neg : pos    =      1.8 : 1.0\n",
      "         contains(never) = False             neg : pos    =      1.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "print(classifier.accuracy(testing))\n",
    "classifier.show_informative_features(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96181754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg\n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "blob=TextBlob('the weather is terrible!',classifier=classifier)\n",
    "print(blob.classify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece21a76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
